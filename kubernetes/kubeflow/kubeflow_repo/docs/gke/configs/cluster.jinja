{#
Copyright 2016 Google Inc. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
#}


{% set NAME_PREFIX = env['deployment'] %}
{% set CLUSTER_NAME = NAME_PREFIX %}
{% set CPU_POOL = NAME_PREFIX + '-cpu-pool-' + properties['pool-version'] %}
{% set GPU_POOL = NAME_PREFIX + '-gpu-pool-' + properties['pool-version'] %}

{# Type names are the names to give to deployment manager type providers
   that will be created to represent Kubernetes objects.
   There is type corresponding to each API endpoint.
#}
{% set TYPE_NAME = NAME_PREFIX + '-type' %}
{% set RBAC_TYPE_NAME = TYPE_NAME + '-rbac-v1' %}
{% set APPS_TYPE_NAME = TYPE_NAME + '-apps-v1' %}

{% set VM_OAUTH_SCOPES = ['https://www.googleapis.com/auth/logging.write', 'https://www.googleapis.com/auth/monitoring'] %}

{# A dictionary mapping type name suffixes to the corresponding
   Kubernetes API endpoint.
#}
{% set K8S_ENDPOINTS = {'': 'api/v1', '-v1beta1-extensions': 'apis/extensions/v1beta1', '-rbac-v1': 'apis/rbac.authorization.k8s.io/v1', '-apps-v1': 'apis/apps/v1/'}  %}

{% set COLLECTION_PREFIX = '/api/v1/namespaces/{namespace}/' %}
{% set NAMESPACE_COLLECTION = '/api/v1/namespaces' %}
{% set CM_COLLECTION = COLLECTION_PREFIX + 'configmaps' %}
{% set RC_COLLECTION = COLLECTION_PREFIX + 'replicationcontrollers' %}
{% set SERVICE_COLLECTION = COLLECTION_PREFIX + 'services' %}
{% set PVC_COLLECTION = COLLECTION_PREFIX + 'persistentvolumeclaims' %}
{% set STATEFULSETS_COLLECTION = '/apis/apps/v1/namespaces/{namespace}/statefulsets' %}
{% set CLUSTER_ROLE_BINDING_COLLECTION = '/apis/rbac.authorization.k8s.io/v1/clusterrolebindings' %}

{# Names for service accounts.
   -admin is to be used for admin tasks
   -user is to be used by users for actual jobs.
   -vm is used for the VM service account attached to the GKE VMs.
 #}
{% set KF_ADMIN_NAME = NAME_PREFIX + '-admin' %}
{% set KF_USER_NAME = NAME_PREFIX + '-user' %}
{% set KF_VM_SA_NAME = NAME_PREFIX + '-vm' %}

resources:
- name: {{ KF_ADMIN_NAME }}
  type: iam.v1.serviceAccount
  properties:
    accountId: {{ KF_ADMIN_NAME }}
    displayName: Service Account used for Kubeflow admin actions.

- name: {{ KF_USER_NAME }}
  type: iam.v1.serviceAccount
  properties:
    accountId: {{ KF_USER_NAME }}
    displayName: Service Account used for Kubeflow user actions.

- name: {{ KF_VM_SA_NAME }}
  type: iam.v1.serviceAccount
  properties:
    accountId: {{ KF_VM_SA_NAME }}
    displayName: GCP Service Account to use as VM Service Account for Kubeflow Cluster VMs

- name: {{ CLUSTER_NAME }}
  {% if properties['gkeApiVersion'] == 'v1beta1' %}
  type: gcp-types/container-v1beta1:projects.locations.clusters
  {% else %}
  type: container.v1.cluster
  {% endif %}
  properties:
    parent: projects/{{ env['project'] }}/locations/{{ properties['zone'] }}
    zone: {{ properties['zone'] }}
    cluster:
      name: {{ CLUSTER_NAME }}
      # Create a very small minimal pool. Actual nodes will be managed
      # as additional node pools. This makes it easier to
      initialNodeCount: 1
      {% if properties['stackdriver-kubernetes'] %}
      # TODO: remove alpha when 10.2 is public.
      # https://github.com/kubeflow/kubeflow/issues/821
      enableKubernetesAlpha: true
      # We need 1.10.2 to support Stackdrivier GKE.
      initialClusterVersion: 1.10.2-gke.0
      # Logging and monitoring have default value [logging/monitoring].googleapis.com
      # if not set. We are using the new Stackdricer Kubernetes agents here.
      # See cloud.google.com/monitoring/kubernetes-engine/.
      loggingService: logging.googleapis.com/kubernetes
      monitoringService: monitoring.googleapis.com/kubernetes
      {% else %}
      initialClusterVersion: 1.9.6-gke.1
      {% endif %}
      {% if properties['gkeApiVersion'] == 'v1beta1' %}
      podSecurityPolicyConfig:
        enabled: {{ properties['securityConfig']['podSecurityPolicy'] }}
      {% endif %}
      {% if properties['securityConfig']['privatecluster'] %}
      ipAllocationPolicy:
        createSubnetwork: true
        useIpAliases: true
      masterIpv4CidrBlock: {{ properties['securityConfig']['masterIpv4CidrBlock'] }}
      privateCluster: true
      masterAuthorizedNetworksConfig: {{ properties['securityConfig']['masterAuthorizedNetworksConfig'] }}
      {% endif %}
      nodeConfig:
        machineType: n1-standard-1
        serviceAccount: {{ KF_VM_SA_NAME }}@{{ env['project'] }}.iam.gserviceaccount.com
        {% if properties['securityConfig']['secureNodeMetadata'] %}
        workloadMetadataConfig:
          nodeMetadata: SECURE
        {% endif %}
        oauthScopes: {{ VM_OAUTH_SCOPES }}
  metadata:
    dependsOn:
    - {{ KF_VM_SA_NAME }}

# We manage the node pools as separate resources.
# We do this so that if we want to make changes we can delete the existing resource and then recreate it.
# Updating doesn't work so well because we are limited in what changes GKE's update method supports.

- name: {{ CPU_POOL }}
  {% if properties['gkeApiVersion'] == 'v1beta1' %}
  type: gcp-types/container-v1beta1:projects.locations.clusters.nodePools
  {% else %}
  type: container.v1.nodePool
  {% endif %}
  properties:
    parent: projects/{{ env['project'] }}/locations/{{ properties['zone'] }}/clusters/{{ CLUSTER_NAME }}
    project: {{ properties['project'] }}
    zone: {{ properties['zone'] }}
    clusterId: {{ CLUSTER_NAME }}
    nodePool:
      name: cpu-pool
      initialNodeCount: {{ properties['cpu-pool-initialNodeCount'] }}
      config:
        {% if properties['securityConfig']['secureNodeMetadata'] %}
        workloadMetadataConfig:
          nodeMetadata: SECURE
        {% endif %}
        machineType: n1-standard-8
        serviceAccount: {{ KF_VM_SA_NAME }}@{{ env['project'] }}.iam.gserviceaccount.com
        oauthScopes: {{ VM_OAUTH_SCOPES }}
  metadata:
    dependsOn:
    - {{ CLUSTER_NAME }}

- name: {{ GPU_POOL }}
  {% if properties['gkeApiVersion'] == 'v1beta1' %}
  type: gcp-types/container-v1beta1:projects.locations.clusters.nodePools
  {% else %}
  type: container.v1.nodePool
  {% endif %}
  properties:
    parent: projects/{{ env['project'] }}/locations/{{ properties['zone'] }}/clusters/{{ CLUSTER_NAME }}
    project: {{ properties['securityConfig']['project'] }}
    zone: {{ properties['zone'] }}
    clusterId: {{ CLUSTER_NAME }}
    nodePool:
      name: gpu-pool
      initialNodeCount: {{ properties['gpu-pool-initialNodeCount'] }}
      config:
        {% if properties['securityConfig']['secureNodeMetadata'] %}
        workloadMetadataConfig:
          nodeMetadata: SECURE
        {% endif %}
        machineType: n1-standard-8
        serviceAccount: {{ KF_VM_SA_NAME }}@{{ env['project'] }}.iam.gserviceaccount.com
        oauthScopes: {{ VM_OAUTH_SCOPES }}
        accelerators:
          - acceleratorCount: 1
            acceleratorType: nvidia-tesla-k80

  metadata:
    dependsOn:
    # We can only create 1 node pool at a time.
    - {{ CPU_POOL }}

{# Project defaults to the project of the deployment. #}
- name: {{ properties['ipName']  }}
  type: compute.v1.globalAddress
  properties:
    description: "Static IP for Kubeflow ingress."

{#

Define TypeProviders for different K8s endpoints.
https://cloud.google.com/deployment-manager/docs/configuration/type-providers/process-adding-api
This allows K8s resources to be created using Deployment manager.
We use this to create the minimal resources needed to startup and deploy Kubeflow via the bootstrapper;
e.g. creating namespaces, service accounts, stateful set to run the bootstrapper.

#}
{% for typeSuffix, endpoint in K8S_ENDPOINTS.iteritems() %}
- name: {{ TYPE_NAME }}{{ typeSuffix }}
  type: deploymentmanager.v2beta.typeProvider
  properties:
    options:
      validationOptions:
        # Kubernetes API accepts ints, in fields they annotate with string.
        # This validation will show as warning rather than failure for
        # Deployment Manager.
        # https://github.com/kubernetes/kubernetes/issues/2971
        schemaValidation: IGNORE_WITH_WARNINGS
      # According to kubernetes spec, the path parameter 'name'
      # should be the value inside the metadata field
      # https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md
      # This mapping specifies that
      inputMappings:
      - fieldName: name
        location: PATH
        methodMatch: ^(GET|DELETE|PUT)$
        value: $.ifNull($.resource.properties.metadata.name, $.resource.name)
      - fieldName: metadata.name
        location: BODY
        methodMatch: ^(PUT|POST)$
        value: $.ifNull($.resource.properties.metadata.name, $.resource.name)
      - fieldName: Authorization
        location: HEADER
        value: >
          $.concat("Bearer ", $.googleOauth2AccessToken())
    descriptorUrl: https://$(ref.{{ CLUSTER_NAME }}.endpoint)/swaggerapi/{{ endpoint }}

{% endfor %}

{# Enable the resource manager API. This is needed below to get IAM policy.
 If activating multiple APIs you might want to serialize them.

 We use an action and not the type deploymentmanager.v2.virtual.enableService
 because we only want to create it; we don't want to delete it.
 Deleting the service corresponds to deactivating the API and that causes problems.
 #}
- name: resource-manager-api
  action: 'gcp-types/servicemanagement-v1:servicemanagement.services.enable'
  properties:
    consumerId: {{ 'project:' + env['project'] }}
    serviceName: cloudresourcemanager.googleapis.com

{# Enable cloud endpoints. This is used to provision DNS names.

TODO(jlewi): Do we need to serialize API activation
#}
- name: endpoints-api
  action: 'gcp-types/servicemanagement-v1:servicemanagement.services.enable'
  properties:
    consumerId: {{ 'project:' + env['project'] }}
    serviceName: endpoints.googleapis.com

- name: iam-api
  action: 'gcp-types/servicemanagement-v1:servicemanagement.services.enable'
  properties:
    consumerId: {{ 'project:' + env['project'] }}
    serviceName: iam.googleapis.com

{# Get the IAM policy first so that we do not remove any existing bindings. #}
- name: get-iam-policy-add
  action: gcp-types/cloudresourcemanager-v1:cloudresourcemanager.projects.getIamPolicy
  metadata:
      dependsOn:
        - resource-manager-api
        - iam-api
      runtimePolicy:
        - UPDATE_ALWAYS
  properties:
      resource: {{ env["project"] }}
{# Set the IAM policy patching the existing policy with what ever is currently in the
  config.

  We need to make the cloudservices account a GKE cluster admin because deployment manager
  users the cloudservices account; so this will be the identity used with the K*s cluster.

  Note: This will fail if the cloudservices account doesn't have IamProjectAdmin
  permissions.
#}
- name: set-iam-policy-add
  action: gcp-types/cloudresourcemanager-v1:cloudresourcemanager.projects.setIamPolicy
  metadata:
      runtimePolicy:
        - UPDATE_ON_CHANGE
  properties:
    resource: {{ env["project"] }}
    policy: $(ref.get-iam-policy-add)
    gcpIamPolicyPatch:
        add:
        - role: roles/container.admin
          members:
            {# Deployment manager uses cloudservices account. #}
            - {{ 'serviceAccount:' + env['project_number'] + '@cloudservices.gserviceaccount.com' }}

        {# Grant permissions needed to push the app to a cloud repository. #}
        - role: roles/source.admin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        {# servicemanagement.admin is needed by CloudEndpoints controller
           so we can create a service to get a hostname.
         #}
        - role: roles/servicemanagement.admin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}
        {# Network admin is needed to enable IAP and configure network settings
           like backend timeouts and health checks.
        #}
        - role: roles/compute.networkAdmin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/storage.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/bigquery.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/dataflow.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/logging.logWriter
          members:
            {# VM service account is used to write logs. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/monitoring.metricWriter
          members:
            {# VM service account is used to write monitoring data. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/storage.objectViewer
          members:
            {# VM service account is used to pull image from gcr. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        {% if 'users' in properties %}
        {% if properties['users'] %}
        - role: roles/iap.httpsResourceAccessor
          members:
            {% for user in properties['users'] %}
            - {{ user }}
            {% endfor %}
        {% endif %}
        {% endif %}
# Use a second get-set IAM policy pair to have a fresh etag.
- name: get-iam-policy-delete
  action: gcp-types/cloudresourcemanager-v1:cloudresourcemanager.projects.getIamPolicy
  metadata:
      dependsOn:
       - set-iam-policy-add
      runtimePolicy:
        - UPDATE_ALWAYS
  properties:
      resource: {{ env["project"] }}
- name: set-iam-policy-delete
  action: gcp-types/cloudresourcemanager-v1:cloudresourcemanager.projects.setIamPolicy
  metadata:
      runtimePolicy:
        - DELETE
  properties:
    resource: {{ env["project"] }}
    policy: $(ref.get-iam-policy-delete)
    gcpIamPolicyPatch:
        remove:
        {# Grant permissions needed to push the app to a cloud repository. #}
        - role: roles/source.admin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        {# servicemanagement.admin is needed by CloudEndpoints controller
           so we can create a service to get a hostname.
         #}
        - role: roles/servicemanagement.admin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}
        {# Network admin is needed to enable IAP and configure network settings
           like backend timeouts and health checks.
        #}
        - role: roles/compute.networkAdmin
          members:
            - {{ 'serviceAccount:' + KF_ADMIN_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/storage.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/bigquery.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/dataflow.admin
          members:
            - {{ 'serviceAccount:' + KF_USER_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/logging.logWriter
          members:
            {# VM service account is used to write logs. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/monitoring.metricWriter
          members:
            {# VM service account is used to write monitoring data. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        - role: roles/storage.objectViewer
          members:
            {# VM service account is used to pull image from gcr. #}
            - {{ 'serviceAccount:' + KF_VM_SA_NAME + '@' + env['project'] + '.iam.gserviceaccount.com' }}

        {% if 'users' in properties %}
        {% if properties['users'] %}
        - role: roles/iap.httpsResourceAccessor
          members:
            {% for user in properties['users'] %}
            - {{ user }}
            {% endfor %}
        {% endif %}
        {% endif %}
    {# This changes every time to ensure a fresh etag is obtained. #}
    quotaUser: {{ env["current_time"] }}
{# A note about K8s resources.
The type value should be defined using a reference to the corresponding type provider.
Using references will ensure the K8s resource has
an explicit dependency on the type provider. This will ensure resources aren't created
until their type provider is created and that the resources are deleted before
the corresponding type provider.
#}

{#  Namespace for bootstrapper. #}
- name: admin-namespace
  type: {{ env['project'] }}/$(ref.{{ TYPE_NAME }}.name):{{ NAMESPACE_COLLECTION }}
  properties:
    apiVersion: v1
    kind: Namespace
    metadata:
      name: kubeflow-admin
    spec:

{# The deployment manager uses the cloudservices account. We need to create
   a cluster role binding making the cloudservices account cluster admin
   so that we can then create other cluster role bindings.
#}
- name: dm-rbac
  type: {{ env['project'] }}/$(ref.{{ RBAC_TYPE_NAME }}.name):{{ CLUSTER_ROLE_BINDING_COLLECTION }}
  properties:
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: cloud-services-cluster-admin
    subjects:
      - kind: User
        name: {{ env['project_number'] + '@cloudservices.gserviceaccount.com' }}
    roleRef:
      kind: ClusterRole
      name: cluster-admin
      apiGroup: rbac.authorization.k8s.io
  metadata:
    dependsOn:
      - admin-namespace

{# Make the default service account in the kubeflow-admin namespace a cluster admin.
   Cluster admin privileges are needed by the bootstrapper.
#}
- name: bootstrap-rbac
  type: {{ env['project'] }}/$(ref.{{ RBAC_TYPE_NAME }}.name):{{ CLUSTER_ROLE_BINDING_COLLECTION }}
  properties:
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: kubeflow-cluster-admin
    subjects:
      - kind: ServiceAccount
        name: default
        namespace: kubeflow-admin
    roleRef:
      kind: ClusterRole
      name: cluster-admin
      apiGroup: rbac.authorization.k8s.io
  metadata:
    dependsOn:
      - admin-namespace
      - dm-rbac

{# Create a persistent volume to store the ksonnet app.
#}
- name: bootstrap-pvc
  type: {{ env['project'] }}/$(ref.{{ TYPE_NAME }}.name):{{ PVC_COLLECTION }}
  properties:
    apiVersion: v1
    kind: PersistentVolumeClaim
    {# Namespace is a property because its used by deployment manager in
       the URL #}
    namespace: kubeflow-admin
    metadata:
      name: kubeflow-ksonnet-pvc
      labels:
        app: kubeflow-ksonnet
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi

  metadata:
    dependsOn:
      - admin-namespace

{# ConfigMap for the bootstrapper #}
- name: bootstrap-configmap
  type: {{ env['project'] }}/$(ref.{{ TYPE_NAME }}.name):{{ CM_COLLECTION }}
  properties:
    apiVersion: v1
    {# Namespace is a property because its used bye deployment manager in
       the URL #}
    kind: ConfigMap
    namespace: kubeflow-admin
    metadata:
      name: kubeflow-bootstrapper
      namespace: kubeflow-admin
    data:
      {# We need to escape newlines so that they get preserved in the configmap. #}
      config.yaml: "{{ properties["bootstrapperConfig"]|replace("\n", "\\n") }}"

  metadata:
      dependsOn:
        - admin-namespace

{# Stateful set for the bootstrapper #}
- name: bootstrap-statefulset
  type: {{ env['project'] }}/$(ref.{{ APPS_TYPE_NAME }}.name):{{ STATEFULSETS_COLLECTION }}
  properties:
    apiVersion: apps/v1
    {# Namespace is a property because its used bye deployment manager in
       the URL #}
    kind: StatefulSet
    namespace: kubeflow-admin
    metadata:
      name: kubeflow-bootstrapper
      namespace: kubeflow-admin
    spec:
      selector:
        matchLabels:
          app: kubeflow-bootstrapper
      serviceName: kubeflow-bootstrapper
      template:
        metadata:
          name: kubeflow-bootstrapper
          labels:
            app: kubeflow-bootstrapper
        spec:
          containers:
          - name: kubeflow-bootstrapper
            image: {{ properties["bootstrapperImage"] }}
            workingDir: /opt/bootstrap
            command:
              - /opt/kubeflow/bootstrapper
              - --in-cluster=true
              - --apply=true
              - --namespace=kubeflow
              - --config=/etc/kubeflow/config.yaml
            env:
              - name: GOOGLE_APPLICATION_CREDENTIALS
                value: /var/run/secrets/sa/admin-gcp-sa.json
            volumeMounts:
            - name: kubeflow-ksonnet-pvc
              mountPath: /opt/bootstrap
            - name: kubeflow-bootstrapper
              mountPath: /etc/kubeflow
            - name: kubeflow-admin-sa
              readOnly: true
              mountPath: /var/run/secrets/sa
          volumes:
          - name: kubeflow-ksonnet-pvc
            persistentVolumeClaim:
              claimName: kubeflow-ksonnet-pvc
          - name: kubeflow-bootstrapper
            configMap:
              name: kubeflow-bootstrapper
          - name: kubeflow-admin-sa
            secret:
              secretName: admin-gcp-sa

  metadata:
    dependsOn:
      - admin-namespace

outputs:
{% for typeSuffix, endpoint in K8S_ENDPOINTS.iteritems() %}
- name: clusterType{{ typeSuffix }}
  value: {{ TYPE_NAME }}{{ typeSuffix }}
{% endfor %}
